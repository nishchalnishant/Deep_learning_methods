**Pros**

- Easy to interpret, implement and train. Doesn’t require too much computational power.
- Makes no assumption of the class distribution.
- Fast in classifying unknown records.
- Can easily accommodate new data points.
- Is very efficient when features are linearly separable.

**Cons:**

- Tries to predict precise probabilistic outcomes, which leads to overfitting in high dimensions.
- Since it has a linear decision surface, it can’t solve non-linear problems.
- Tough to obtain complex relations other than linear relations.
- Requires very little or no multicollinearity.
- Needs a large dataset and sufficient training examples for all the categories to make correct predictions.
